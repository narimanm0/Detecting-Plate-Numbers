{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d91b38f7-56e9-4adf-9bc6-ef251cedf583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ed7c82-1361-4f81-849b-696bcafcd7b0",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dcc1778-e89c-4a56-8653-5353487cef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "CHARS = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ -\"\n",
    "CHAR_TO_NUM = {char: i for i, char in enumerate(CHARS)}\n",
    "NUM_TO_CHAR = {i: char for i, char in enumerate(CHARS)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c1ec52-053c-4f44-9762-31c6c0462398",
   "metadata": {},
   "source": [
    "## 2. Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ebe0d4-8bf8-4dd7-992a-01ecb0612e74",
   "metadata": {},
   "source": [
    "#### 2.1 Load and preprocess image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae406b5-7acb-40f8-b462-92f65b4b4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, img_height=IMG_HEIGHT, img_width=IMG_WIDTH):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=1)\n",
    "    img = tf.image.resize(img, [img_height, img_width])\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54e587-0167-47fb-b7ac-00be81d53b7d",
   "metadata": {},
   "source": [
    "#### 2.2 Encode text to integer sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8393be0-10a4-4e57-b547-0e461442a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(text):\n",
    "    return [CHAR_TO_NUM[c] for c in text if c in CHAR_TO_NUM]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474461df-7a35-4113-8c30-2b12d24f3751",
   "metadata": {},
   "source": [
    "#### 2.3 Create tf.data.Dataset from CSV and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "232c2449-444c-42a7-9c27-6c704575c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(csv_path, image_dir, img_height=IMG_HEIGHT, img_width=IMG_WIDTH):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    filenames = df['filename'].values\n",
    "    texts = df['plate_number'].values\n",
    "\n",
    "    def generator():\n",
    "        for filename, text in zip(filenames, texts):\n",
    "            img_path = os.path.join(image_dir, filename)\n",
    "            img = preprocess_image(img_path, img_height, img_width)\n",
    "            label = encode_text(text)\n",
    "            yield img, label\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(img_height, img_width, 1), dtype=tf.float32),\n",
    "            tf.RaggedTensorSpec(shape=[None], dtype=tf.int32)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    max_len = max(len(t) for t in texts)\n",
    "    dataset = dataset.map(lambda x, y: (\n",
    "        x,\n",
    "        tf.pad(y, [[0, max_len - tf.shape(y)[0]]], constant_values=-1)\n",
    "    ))\n",
    "\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e86af-e707-4dd4-8ef3-f4f361b15151",
   "metadata": {},
   "source": [
    "## 3. MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3f643a9-4e70-42b6-8a33-9b7cf711bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crnn_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1), num_chars=len(CHARS)):\n",
    "    inputs = layers.Input(shape=input_shape, name='image')\n",
    "\n",
    "    x = layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    x = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "    new_shape = ((input_shape[0] // 8), (input_shape[1] // 8) * 128)\n",
    "    x = layers.Reshape(target_shape=new_shape)(x)\n",
    "\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "\n",
    "    outputs = layers.Dense(num_chars + 1, activation='softmax', name='dense')(\n",
    "        x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
